# [Learning both Weights and Connections for Efficient Neural Networks](https://arxiv.org/abs/1506.02626)

Content description
This code is a reproduction of the PyTorch version of the 2015 paper as the title. The content of the paper is to perform network pruning on CNN to remove unimportant weights, thereby significantly reducing the size of the model. The author of the paper added Quantization and Huffman Encoding on the basis of this paper, and proposed a well-known three-stage method - Deep Compression in 2016. The former is the initial version of the latter. The author of the original repository seems to have confused them. To distinguish it from the latter, I changed the repository name to Simple pruning.

My code is from fork, and the original warehouse is DeepCompression-PyTorch . In the process of running through, I modified some details, and added some Chinese comments to the key code according to my own understanding, hoping to help those who study the original code and research papers.

Operating environment
Windows 10

Hardware: AMD R5 3600X + RTX2060 super (I used a single GPU, the original warehouse supports dual GPUs, I removed it to simplify the code)

pytorch1.2 GPU version (the original warehouse did not specify the version of PyTorch, I used 1.2)

Steps for usage
The original repository was run from the command line, probably Linux. The IDE I use is pycharm . For the convenience of debugging, I remove the command line and run the corresponding .py file directly in the IDE.

1. Prepare the cifar10 dataset
Create a new folder cifar10 and checkpoints under the project, and put the downloaded cifar-10-python.tar.gz file in cifar10. (If you want to change the location, you can set the DATA in config.py yourself)

2. Pretraining
Run train.py , you will get a **.t7 file** in the checkpoints folder, which mainly contains the weights of the pre-trained model. (Note: The default training is 200 epochs, which takes a long time. You can change the epochs to a smaller size )

3. Pruning and retraining
Run prune.py , you will get multiple **.t7 files** in the checkpoints folder, which are the model weights in different stages of pruning. (Similarly, you can make finetune_steps smaller before running, and then run it normally)

Code implementation details
The original paper (15 years old) targets LeNet, AlexNet and VGG-16, while this recurrence targets RestNet and Wide ResNet (see paper Wide Residual Networks ) for pruning.

In theory, as the pruning ratio increases, the weight of the model should become less and less, so the .t7 file generated by the pruning process will become smaller and smaller, but it will not actually decrease. This is because the weights are stored in the Tensor tensor, and the pruning process just sets some elements in the Tensor to 0, but it still occupies space. When pytorch saves weights, each Tensor is regarded as an object. Tensor is a dense matrix, which can only be saved as a whole, and the values ​​of certain elements cannot be saved separately . If you want to really achieve model compression, you need to consider sparse matrices (refer to torch.sparse ) or other methods.

Choice of weight threshold :

The idea of ​​​​the original paper is to set a threshold for weights, and weights below this threshold are considered unimportant and therefore will be "cut out", but the original paper does not explain how to choose this threshold .
The method used for this reproduction is to obtain all the remaining (not clipped) weights and take their quantiles . For example: if the pruning ratio is 50%, take the median of all weights.
Other content will be added in time.
